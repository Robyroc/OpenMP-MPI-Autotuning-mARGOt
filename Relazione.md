## Progetto Hybrid MPI-OpenMP Application Autotuning in HPC systems
Il progetto consiste nella creazione di un tool che possa permettere ad applicazioni implementanti le librerie OpenMP e MPI l’autotuning. Ho dovuto identificare i parametri che permettono l’ottimizzazione di un’applicazione ibrida parallela e, mediante test, trovare il loro valore che permetta di ridurre al minimo il tempo di esecuzione.

Per iniziare ho familiarizzato con le librerie coinvolte: durante i miei studi ho trattato il tema del parallelismo ma non con un approccio rivolto a sistemi HPC. Le librerie che ho studiato non sono usate direttamente nel HPC poiché ci sono alternative migliori ormai adottate da tutti. Se MPI nasce come standard per le comunicazioni tra processi, OpenMP è diventata senza dubbio la libreria più usata nell’ambito del multithreading per le applicazioni ad alte prestazioni. Per far pratica ho dunque scritto un programma molto semplice che si limita a svolgere il prodotto tra matrici (il valore di ogni elemento per comodità è dipendente dalla posizione), in seguito ne ho implementata una versione parallela con entrambe le librerie. Dopo aver fatto un paio di esecuzioni di prova, ho notato che per quest’applicazione l’approccio basato su OpenMP senza MPI ha portato i risultati migliori: del resto l’algoritmo implementato prevede un utilizzo dei dati difficile da serializzare e quindi basarsi sui thread è più efficiente. Bisogna considerare tuttavia che ho compiuto questo test solo sul mio portatile, dotato di un processore dual-core: il numero di core influenza molto i risultati raggiunti poiché è correlato al numero massimo di esecuzioni in parallelo. Pensavo che il numero di core potesse aiutarmi a ridurre il campo di analisi del problema: le esecuzioni in cui il prodotto tra numero di processi e di thread superava quello dei core del mio PC si rivelavano in media più lente, superando in alcuni casi l’esecuzione non parallela. Questi ritardi erano dovuti sia a overhead per la creazione dei processi, sia ad accodamenti di scheduling. Questa tendenza è rimasta anche nelle esecuzioni successive, con qualche eccezione.

Dopo aver realizzato la mia applicazione ibrida tunabile, sono stato introdotto al progetto mARGOt: si tratta di un tool sviluppato dal Politecnico di Milano per l’ottimizzazione di un qualunque aspetto di un’applicazione. mARGOt permette di estrapolare dal codice una serie di knobs e monitor: agendo opportunamente sui primi si può ottimizzare il valore dei secondi. mARGOt si basa sul principio MAPE-K, cioè Monitor, Analyze, Plan ed Execute basato sulla Knowledge: secondo dei dati già raccolti permette di scegliere la configurazione che meglio si adatta al problema. Il tool richiede di modificare il codice in modo da notificare quando bisogna iniziare e finire le misurazioni, rendendo l’implementazione diretta poco portabile. Inoltre la maggior parte degli utilizzatori di applicazioni HPC sono specializzati in altri ambiti, rendendo la modifica del codice un compito potenzialmente complesso. Infine potrebbe essere necessario ottimizzare applicazioni non open-source, rendendo la modifica difficile e potenzialmente causa d’instabilità.

Il tuner sopperisce a questo problema, incorporando il codice necessario per mARGOt e occupandosi dell’esecuzione dell’applicazione da ottimizzare. Se all’inizio si occupava anche della compilazione dell’applicazione da tunarsi, ho preferito separare quest’aspetto da quello principale seguendo la direzione della portabilità.

mARGOt si basa sulla Knowledge e definisce la sintassi che essa deve avere: non mette a disposizione tuttavia i mezzi per ottenerla. Serviva dunque un ulteriore tool in grado di estrapolare i dati dal programma, cioè testare tutte le possibili configurazioni dei knob e tener traccia dei valori dei monitor. Adattando un po’ una copia del codice del tuner ho creato agorizer (il nome deriva da AGORA’, di cui parlerò più avanti). Questo tool è accompagnato da un suo file di configurazione che permette di decidere i valori dei knob e il numero di ripetizioni per punto operativo. Per ogni esecuzione monitora il tempo impiegato e ne calcola una media. Raccoglie tutti i dati e crea un file con sintassi compatibile con mARGOt.

L’esecuzione di agorizer è tuttavia molto dispendiosa in termini di tempo e risorse: dovendo analizzare ogni configurazione possibile molte volte, finisce per essere un costo sopportabile solo se l’esecuzione del programma tunato avverrà ripetutamente. I dati così ottenuti sono inoltre difficili da riutilizzare, rendendo il processo molto gravoso nel caso di architetture molto grandi (cluster di calcolatori). L’alternativa è l’utilizzo di un plug-in di mARGOt che permetta la creazione della Knowledge da remoto: AGORA. Il principale vantaggio nell’interfacciarsi con AGORA risiede nella riutilizzabilità dei dati ottenuti, che permette sia di ridurre il tempo necessario nel caso di grandi architetture, sia la creazione della Knowledge in parallelo su più calcolatori simili. AGORA permetterà inoltre di utilizzare algoritmi più efficienti per l’ottenimento dei dati, riducendo ulteriormente l’impatto temporale. L’unico lato negativo risiede nell’eccessivo accoppiamento tra AGORA e l’applicazione da ottimizzarsi: il plug-in non condivide la Knowledge con i vari calcolatori, bensì questi ultimi si devono sempre e comunque collegare a quest’ultimo per ottenere i dati che servono loro.

I knob utilizzati per i vari test sono principalmente due: numero di thread e di processi. OpenMP fornisce anche la possibilità di scegliere la posizione o una politica di disposizione dei thread. Sfruttando questa funzionalità ho aggiunto un terzo knob introducendo quattro casi, che poi saranno mappati nei corrispettivi valori testuali della variabile d’ambiente OMP_PROC_BIND:

1.	SPREAD, i thread sono sparsi lungo la partizione di memoria in uso;
2.	CLOSE, i thread sono vicini tra loro;
3.	MASTER, i thread sono più vicini possibile al thread principale;
4.	FALSE, la gestione della posizione dei thread è lasciata al sistema. 

Unendo tutti questi elementi otteniamo il progetto AGATHA (acronimo di AGAtha Tunes Hybrid Applications). In esso ho posto qualche script per aiutare l’utente nello svolgimento dei vari passaggi per l’autotuning. L’utente può inoltre configurare completamente i valori entro cui agorizer (o AGORA) dovrà operare, permettendogli di scegliere tra precisione, velocità e copertura come meglio preferisce. Applicando AGATHA al programma sul prodotto tra matrici, ho notato risultati diversi secondo il processore su cui hanno girato: sul mio portatile (dual-core) la configurazione migliore è quella con quattro thread su un solo processo, con politica di mapping SPREAD mentre su un numasaurus (NUMA 4 processori 4 core l’uno) 4 processi, sedici thread e politica SPREAD. Dai dati noto che la differenza più grande si ottiene tunando il numero di processi, mentre i parametri OMP influenzano il risultato solo per qualche punto percentuale.

La programmazione parallela ibrida permette di ottenere sistemi a ottime prestazioni. Sfruttando OpenMP si riesce ad ottenere un livello di capillarità ed efficienza irraggiungibile con il solo MPI. D’altro canto MPI fornisce i mezzi per una scalabilità quasi infinita, rendendosi fondamentale e prevalente nel caso di cluster di grande dimensione. Se sfruttate bene, le librerie si completano, poiché ciascuna sopperisce ai difetti dell’altra. Se sfruttate male, finiscono per appesantire e rallentare il programma, causando perdite di efficienza. L’utilizzo della programmazione parallela ibrida permette comunque di generare applicazioni più adattabili all’architettura su cui girano e al carico cui questa è sottoposta: è senza dubbio da preferire qualora ve ne sia la possibilità. Una buona dose di ottimizzazione è sempre necessaria poiché le variabili da considerare sono molte e la loro correlazione complessa.
